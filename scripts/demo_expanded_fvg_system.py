"""
üöÄ DEMO EXPANSI√ìN MULTI-TIMEFRAME CON DATOS REALES
Sistema completo de detecci√≥n expandida con alertas

Fecha: Agosto 12, 2025
Oficina: Detecci√≥n Expandida - Piso 3
Estado: Demo Integraci√≥n Completa
"""

import pandas as pd
import numpy as np
import asyncio
import sys
import os
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List

# Agregar src al path
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

from analysis.fvg_detector import FVGDetector
from analysis.multi_timeframe_detector import MultiTimeframeFVGDetector
from analysis.fvg_alert_system import FVGAlertSystem, AlertType, AlertPriority

class ExpandedFVGSystem:
    """
    üîç SISTEMA FVG EXPANDIDO COMPLETO
    
    Integra:
    - Detecci√≥n multi-timeframe
    - An√°lisis de confluencias
    - Sistema de alertas
    - M√©tricas por sesi√≥n
    - Datos reales
    """
    
    def __init__(self):
        """Inicializa el sistema expandido"""
        # Componentes principales
        self.multi_detector = MultiTimeframeFVGDetector("EURUSD")
        self.alert_system = FVGAlertSystem({
            'max_alerts_per_minute': 20,
            'min_priority': AlertPriority.LOW,
            'throttling_enabled': False  # Desactivar para demo
        })
        
        # Paths de datos
        self.data_path = Path(__file__).parent.parent / "data"
        self.latest_data_folder = self._get_latest_data_folder()
        
        print("üöÄ Sistema FVG Expandido inicializado")
        print(f"üìÇ Datos: {self.latest_data_folder}")
    
    def _get_latest_data_folder(self):
        """Obtiene la carpeta de datos m√°s reciente"""
        data_folders = [f for f in self.data_path.iterdir() if f.is_dir() and f.name.startswith("2025")]
        return sorted(data_folders, key=lambda x: x.name, reverse=True)[0]
    
    def load_multi_timeframe_data(self, symbol="EURUSD", limit_per_tf=None):
        """
        Carga datos reales para m√∫ltiples timeframes
        
        Args:
            symbol: S√≠mbolo a cargar
            limit_per_tf: L√≠mite de velas por timeframe
            
        Returns:
            Dict con DataFrames por timeframe
        """
        timeframes = ['M5', 'M15', 'H1', 'H4']
        data_by_tf = {}
        
        print(f"üìä Cargando datos multi-timeframe para {symbol}")
        
        for tf in timeframes:
            filename = f"velas_{symbol}_{tf}_3meses.csv"
            filepath = self.latest_data_folder / filename
            
            if not filepath.exists():
                print(f"‚ö†Ô∏è Archivo no encontrado: {filename}")
                continue
            
            try:
                df = pd.read_csv(filepath)
                
                if limit_per_tf:
                    df = df.tail(limit_per_tf)
                
                df['datetime'] = pd.to_datetime(df['datetime'])
                data_by_tf[tf] = df
                
                print(f"   ‚úÖ {tf}: {len(df)} velas | "
                      f"{df['datetime'].min().strftime('%m-%d %H:%M')} a "
                      f"{df['datetime'].max().strftime('%m-%d %H:%M')}")
                
            except Exception as e:
                print(f"   ‚ùå Error cargando {tf}: {e}")
        
        return data_by_tf
    
    async def run_complete_analysis(self, symbol="EURUSD", limit=500):
        """
        Ejecuta an√°lisis completo multi-timeframe con alertas
        
        Args:
            symbol: S√≠mbolo a analizar
            limit: L√≠mite de velas por timeframe
        """
        print(f"\nüîç AN√ÅLISIS COMPLETO MULTI-TIMEFRAME: {symbol}")
        print("=" * 70)
        
        try:
            # 1. Cargar datos multi-timeframe
            data_by_tf = self.load_multi_timeframe_data(symbol, limit)
            
            if not data_by_tf:
                print("‚ùå No se pudieron cargar datos")
                return
            
            # 2. Ejecutar an√°lisis multi-timeframe
            print(f"\nüîÑ Procesando an√°lisis multi-timeframe...")
            analysis = self.multi_detector.analyze_multi_timeframe_data(data_by_tf)
            
            # 3. Generar alertas basadas en an√°lisis
            print(f"\nüö® Generando alertas...")
            alerts = self.multi_detector.generate_alerts(analysis)
            
            # 4. Enviar alertas espec√≠ficas
            await self._process_alerts(alerts, symbol)
            
            # 5. An√°lisis adicional de patrones
            await self._analyze_advanced_patterns(analysis, symbol)
            
            # 6. Mostrar estad√≠sticas finales
            self._show_final_statistics(analysis)
            
            return analysis
            
        except Exception as e:
            print(f"‚ùå Error en an√°lisis completo: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    async def _process_alerts(self, alerts: List[Dict], symbol: str):
        """Procesa y env√≠a alertas generadas"""
        if not alerts:
            print("   ‚ÑπÔ∏è No se generaron alertas")
            return
        
        print(f"   üì® Procesando {len(alerts)} alertas...")
        
        for alert in alerts:
            alert_type_map = {
                'CONFLUENCE': AlertType.CONFLUENCE,
                'LARGE_FVG': AlertType.LARGE_FVG,
                'MARKET_BIAS': AlertType.MARKET_BIAS,
                'SESSION_CONCENTRATION': AlertType.SESSION_CONCENTRATION
            }
            
            alert_type = alert_type_map.get(alert['type'], AlertType.NEW_FVG)
            priority_map = {
                'LOW': AlertPriority.LOW,
                'MEDIUM': AlertPriority.MEDIUM,
                'HIGH': AlertPriority.HIGH,
                'CRITICAL': AlertPriority.CRITICAL
            }
            priority = priority_map.get(alert['priority'], AlertPriority.MEDIUM)
            
            await self.alert_system.send_alert(
                alert_type=alert_type,
                title=alert['message'],
                message=f"Detalles: {alert.get('data', {})}",
                symbol=symbol,
                priority=priority,
                timeframe=alert.get('timeframe'),
                data=alert.get('data', {})
            )
    
    async def _analyze_advanced_patterns(self, analysis, symbol: str):
        """An√°lisis avanzado de patrones"""
        print(f"\nüìà AN√ÅLISIS AVANZADO DE PATRONES")
        print("-" * 50)
        
        # An√°lisis de densidad FVG por timeframe
        print("üìä Densidad FVG por Timeframe:")
        for tf, fvgs in analysis.timeframe_data.items():
            density = len(fvgs) / 100  # FVGs por 100 velas
            print(f"   {tf:3s}: {density:.2f} FVGs/100 velas")
        
        # An√°lisis de correlaci√≥n entre timeframes
        print(f"\nüîó An√°lisis de Correlaciones:")
        self._analyze_timeframe_correlations(analysis.timeframe_data)
        
        # An√°lisis de timing de confluencias
        if analysis.confluence_fvgs:
            print(f"\n‚è∞ An√°lisis de Confluencias:")
            strong_confluences = [c for c in analysis.confluence_fvgs if c['confluence_strength'] >= 7.0]
            print(f"   Confluencias fuertes: {len(strong_confluences)}/{len(analysis.confluence_fvgs)}")
            
            # Alertas para confluencias fuertes
            for conf in strong_confluences:
                await self.alert_system.send_confluence_alert(conf, symbol)
    
    def _analyze_timeframe_correlations(self, timeframe_data):
        """Analiza correlaciones entre timeframes"""
        timeframes = list(timeframe_data.keys())
        
        for i, tf1 in enumerate(timeframes):
            for tf2 in timeframes[i+1:]:
                fvgs1 = timeframe_data[tf1]
                fvgs2 = timeframe_data[tf2]
                
                # An√°lisis simple de correlaci√≥n por tipo
                bullish1 = sum(1 for fvg in fvgs1 if fvg.type == 'BULLISH')
                bullish2 = sum(1 for fvg in fvgs2 if fvg.type == 'BULLISH')
                
                total1, total2 = len(fvgs1), len(fvgs2)
                
                if total1 > 0 and total2 > 0:
                    ratio1 = bullish1 / total1
                    ratio2 = bullish2 / total2
                    correlation = 1 - abs(ratio1 - ratio2)  # Correlaci√≥n simple
                    
                    print(f"   {tf1}-{tf2}: {correlation:.2f} correlaci√≥n")
    
    def _show_final_statistics(self, analysis):
        """Muestra estad√≠sticas finales del an√°lisis"""
        print(f"\nüìä ESTAD√çSTICAS FINALES")
        print("=" * 50)
        
        # M√©tricas del detector multi-timeframe
        metrics = self.multi_detector.get_global_metrics()
        print(f"üéØ Total detecciones: {metrics.get('total_detections', 0)}")
        print(f"üîó Confluencias: {metrics.get('confluence_detections', 0)}")
        
        # Distribuci√≥n por sesi√≥n
        session_dist = metrics.get('session_distribution', {})
        if session_dist:
            print(f"\nüïí Distribuci√≥n por Sesi√≥n:")
            for session, count in session_dist.items():
                percentage = (count / sum(session_dist.values()) * 100) if session_dist.values() else 0
                print(f"   {session:8s}: {count:3d} ({percentage:5.1f}%)")
        
        # M√©tricas del sistema de alertas
        alert_metrics = self.alert_system.get_metrics()
        print(f"\nüö® M√©tricas de Alertas:")
        print(f"   üì® Alertas enviadas: {alert_metrics['sent_alerts']}")
        print(f"   üîá Alertas suprimidas: {alert_metrics['suppressed_alerts']}")
        print(f"   ‚ùå Fallos de env√≠o: {alert_metrics['failed_sends']}")
    
    async def demo_real_time_simulation(self, symbol="EURUSD", timeframe="M5", duration_minutes=10):
        """
        Simula procesamiento en tiempo real
        
        Args:
            symbol: S√≠mbolo a simular
            timeframe: Timeframe base
            duration_minutes: Duraci√≥n de la simulaci√≥n
        """
        print(f"\n‚ö° SIMULACI√ìN TIEMPO REAL")
        print(f"S√≠mbolo: {symbol} | TF: {timeframe} | Duraci√≥n: {duration_minutes}min")
        print("=" * 60)
        
        # Cargar datos para simulaci√≥n
        data = self.load_multi_timeframe_data(symbol, limit_per_tf=1000)
        
        if timeframe not in data:
            print(f"‚ùå No hay datos para {timeframe}")
            return
        
        df = data[timeframe]
        simulation_candles = df.tail(duration_minutes * 12).copy()  # 12 velas de M5 por hora
        
        print(f"üîÑ Simulando {len(simulation_candles)} velas...")
        print("(Presiona Ctrl+C para detener)\n")
        
        detector = FVGDetector()
        candle_buffer = []
        
        try:
            for i, (_, row) in enumerate(simulation_candles.iterrows()):
                # Preparar vela actual
                candle = {
                    'time': row['datetime'],
                    'open': float(row['open']),
                    'high': float(row['high']),
                    'low': float(row['low']),
                    'close': float(row['close']),
                    'volume': int(row['volume']),
                    'symbol': symbol,
                    'timeframe': timeframe
                }
                
                candle_buffer.append(candle)
                
                # Mostrar vela actual
                time_str = candle['time'].strftime('%H:%M')
                print(f"‚è∞ {i+1:3d}. {time_str} | "
                      f"OHLC: {candle['open']:.5f} {candle['high']:.5f} "
                      f"{candle['low']:.5f} {candle['close']:.5f}")
                
                # Detectar FVGs si tenemos suficientes velas
                if len(candle_buffer) >= 3:
                    # Detectar FVG bullish
                    bullish_fvg = detector.detect_bullish_fvg(candle_buffer[-3:])
                    if bullish_fvg:
                        gap_pips = bullish_fvg.gap_size * 10000
                        print(f"     üü¢ FVG BULLISH: {gap_pips:.1f} pips")
                        await self.alert_system.send_fvg_alert(
                            bullish_fvg.to_dict(), symbol, timeframe
                        )
                    
                    # Detectar FVG bearish
                    bearish_fvg = detector.detect_bearish_fvg(candle_buffer[-3:])
                    if bearish_fvg:
                        gap_pips = bearish_fvg.gap_size * 10000
                        print(f"     üî¥ FVG BEARISH: {gap_pips:.1f} pips")
                        await self.alert_system.send_fvg_alert(
                            bearish_fvg.to_dict(), symbol, timeframe
                        )
                
                # Pausa para simular tiempo real
                await asyncio.sleep(0.5)
        
        except KeyboardInterrupt:
            print("\n‚èπÔ∏è Simulaci√≥n detenida por usuario")
        
        # Mostrar resumen de simulaci√≥n
        print(f"\nüìä RESUMEN SIMULACI√ìN:")
        alert_metrics = self.alert_system.get_metrics()
        print(f"   üì® Alertas generadas: {alert_metrics['total_alerts']}")
        print(f"   ‚ö° Velas procesadas: {len(candle_buffer)}")

async def main():
    """Funci√≥n principal de demostraci√≥n"""
    print("üöÄ DEMO EXPANSI√ìN MULTI-TIMEFRAME - PISO 3")
    print("=" * 70)
    print()
    
    # Crear sistema expandido
    system = ExpandedFVGSystem()
    
    try:
        # 1. An√°lisis completo multi-timeframe
        print("1Ô∏è‚É£ EJECUTANDO AN√ÅLISIS MULTI-TIMEFRAME")
        analysis = await system.run_complete_analysis("EURUSD", limit=300)
        
        if analysis:
            # 2. Pausa entre demos
            print("\n" + "="*70)
            input("Presiona Enter para continuar a la simulaci√≥n en tiempo real...")
            
            # 3. Simulaci√≥n tiempo real
            print("\n2Ô∏è‚É£ SIMULACI√ìN TIEMPO REAL")
            await system.demo_real_time_simulation("EURUSD", "M5", duration_minutes=5)
            
            # 4. Mostrar historial de alertas
            print("\n3Ô∏è‚É£ HISTORIAL DE ALERTAS")
            print("=" * 40)
            
            alert_history = system.alert_system.get_alert_history(10)
            for i, alert in enumerate(alert_history[:10], 1):
                time_str = pd.to_datetime(alert['timestamp']).strftime('%H:%M:%S')
                print(f"{i:2d}. [{alert['priority']}] {time_str} - {alert['title']}")
        
        print("\n‚úÖ DEMOSTRACI√ìN COMPLETA FINALIZADA!")
        
        print("\nüéØ CAPACIDADES IMPLEMENTADAS:")
        print("   ‚úÖ Detecci√≥n multi-timeframe (M5, M15, H1, H4)")
        print("   ‚úÖ An√°lisis de confluencias entre timeframes")
        print("   ‚úÖ Sistema de alertas inteligente")
        print("   ‚úÖ Estad√≠sticas por sesi√≥n de trading")
        print("   ‚úÖ Simulaci√≥n tiempo real")
        print("   ‚úÖ M√©tricas y monitoreo completo")
        
        print("\nüöÄ PR√ìXIMOS PASOS SUGERIDOS:")
        print("   1. Implementar Oficina de An√°lisis (calidad FVG)")
        print("   2. Desarrollar Oficina de IA (predicciones ML)")
        print("   3. Crear Oficina de Trading (se√±ales autom√°ticas)")
        print("   4. Integrar con sistema de trading en vivo")
        
    except Exception as e:
        print(f"‚ùå Error en demostraci√≥n: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())
